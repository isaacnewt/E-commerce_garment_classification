{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "285b4a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "# from imutils import paths\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "d794f535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "b3000d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('.')\n",
    "\n",
    "# Load files,r'' C:/Users/good/Documents/ziki/hackatons/vhidya\n",
    "# Define image and label paths\n",
    "image_dir = 'C:/Users/good/Documents/ziki/hackatons/vhidya/garments_vision/data/train_LbELtWX/train'  # Update with the actual image folder path\n",
    "\n",
    "test_image_dir = 'C:/Users/good/Documents/ziki/hackatons/vhidya/garments_vision/data/test_ScVgIM0/test'\n",
    "\n",
    "# Load files\n",
    "data = pd.read_csv(DATA_PATH / 'data/train_LbELtWX/train.csv', dtype=str)\n",
    "test = pd.read_csv(DATA_PATH / 'data/test_ScVgIM0/test.csv', dtype=str)\n",
    "ss = pd.read_csv(DATA_PATH / 'data/sample_submission_I5njJSF.csv')\n",
    "\n",
    "data['id']=data['id'].apply(lambda x: f'{x}.png')\n",
    "test['id']=test['id'].apply(lambda x: f'{x}.png')\n",
    "\n",
    "# Ensure that classes are integers\n",
    "data['label'] = data['label'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "efff6a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1.png', '10.png', '100.png', '1000.png', '10000.png', '10001.png', '10002.png', '10003.png', '10004.png', '10005.png']\n"
     ]
    }
   ],
   "source": [
    "imgs = os.listdir(image_dir)\n",
    "print(imgs[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "9b1a4595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ImageDataGenerator instances\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2, #Use 20% of training data for validation\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "898e2795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 48000 validated image filenames belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "#Create generators\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    data,\n",
    "    directory = image_dir,\n",
    "    x_col='id',\n",
    "    y_col='label',\n",
    "    has_extension = True,  # save_format = 'png',\n",
    "    target_size=(128, 128), #You can adjust the size as needed\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    classes=[\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"],\n",
    "    subset='training',\n",
    "    shuffle=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "3d98ae96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12000 validated image filenames belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator=train_datagen.flow_from_dataframe(\n",
    "    data,\n",
    "    directory=image_dir,\n",
    "    x_col='id',\n",
    "    y_col='label',\n",
    "    target_size=(128,128),\n",
    "    batch_size=32,\n",
    "    save_format = 'png',\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    classes=[\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"],\n",
    "    shuffle=True\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b8ece5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "test_datagen=ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "test_generator=test_datagen.flow_from_dataframe(\n",
    "    test_df,\n",
    "    directory = test_image_dir,\n",
    "    x_col='id',\n",
    "    y_col='label',\n",
    "    target_size=(128,128),\n",
    "    batch_size=32,\n",
    "    class_mode= None,\n",
    "    shuffle=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "73728961",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape,num_classes):\n",
    "    model = Sequential([\n",
    "        Conv2D(32,(3,3), activation='relu',input_shape=input_shape),\n",
    "        MaxPooling2D((2,2)),\n",
    "        Conv2D(64,(3,3), activation='relu'),\n",
    "        MaxPooling2D((2,2)),\n",
    "        Conv2D(128, (3,3), activation='relu'),\n",
    "        MaxPooling2D((2,2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "#Image size (128x128) and 3 channels(RGB)\n",
    "input_shape = (128, 128, 3) \n",
    "\n",
    "num_classes = len(train_generator.class_indices) #Number of classes\n",
    "model = build_model(input_shape, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "714e537b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Define callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "model_checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_loss', mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "54e78625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1044/1500 [===================>..........] - ETA: 21:20 - loss: 0.6703 - accuracy: 0.7482"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Graph execution error:\n\nUnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x000002C463A5E040>\nTraceback (most recent call last):\n\n  File \"D:\\Programs\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"D:\\Programs\\Anaconda\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"D:\\Programs\\Anaconda\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 1035, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"D:\\Programs\\Anaconda\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 903, in wrapped_generator\n    for data in generator_fn():\n\n  File \"D:\\Programs\\Anaconda\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 1050, in generator_fn\n    yield x[i]\n\n  File \"D:\\Programs\\Anaconda\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 116, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"D:\\Programs\\Anaconda\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 370, in _get_batches_of_transformed_samples\n    img = image_utils.load_img(\n\n  File \"D:\\Programs\\Anaconda\\lib\\site-packages\\keras\\utils\\image_utils.py\", line 423, in load_img\n    img = pil_image.open(io.BytesIO(f.read()))\n\n  File \"C:\\Users\\good\\AppData\\Roaming\\Python\\Python38\\site-packages\\PIL\\Image.py\", line 3008, in open\n    raise UnidentifiedImageError(\n\nPIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x000002C463A5E040>\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_958]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6740\\1533879925.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m history = model.fit(\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m               \u001b[1;31m# 50,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m: Graph execution error:\n\nUnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x000002C463A5E040>\nTraceback (most recent call last):\n\n  File \"D:\\Programs\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"D:\\Programs\\Anaconda\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"D:\\Programs\\Anaconda\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 1035, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"D:\\Programs\\Anaconda\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 903, in wrapped_generator\n    for data in generator_fn():\n\n  File \"D:\\Programs\\Anaconda\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 1050, in generator_fn\n    yield x[i]\n\n  File \"D:\\Programs\\Anaconda\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 116, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"D:\\Programs\\Anaconda\\lib\\site-packages\\keras\\preprocessing\\image.py\", line 370, in _get_batches_of_transformed_samples\n    img = image_utils.load_img(\n\n  File \"D:\\Programs\\Anaconda\\lib\\site-packages\\keras\\utils\\image_utils.py\", line 423, in load_img\n    img = pil_image.open(io.BytesIO(f.read()))\n\n  File \"C:\\Users\\good\\AppData\\Roaming\\Python\\Python38\\site-packages\\PIL\\Image.py\", line 3008, in open\n    raise UnidentifiedImageError(\n\nPIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x000002C463A5E040>\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_958]"
     ]
    }
   ],
   "source": [
    "#Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs= 2,               # 50,\n",
    "    validation_data = validation_generator,\n",
    "    callbacks = [early_stopping, model_checkpoint]\n",
    "    )\n",
    "\n",
    "#Load the best model\n",
    "model.load_weights('best_model.h5')\n",
    "\n",
    "#Evaluate on the test set\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "\n",
    "print(f'TestAccuracy:{test_acc:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c85c7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('No. of Samples:', train_generator.samples)\n",
    "print('Number of Classes:', len(train_generator.class_indices))\n",
    "print('Samples per Classes:', int(train_generator.samples/len(train_generator.class_indices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5562ac5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We get the third batch\n",
    "train_generator.reset() #resets the generator to the first batch\n",
    "for i in range(3):\n",
    "    x1,y1 = next(train_generator)\n",
    "    y1_int = np.argmax(y1,axis=-1)\n",
    "\n",
    "#Plot the batch images w.r.t. the dataset images.\n",
    "plt.figure(figsize=(4,4))\n",
    "idx=1\n",
    "for i in range(8):\n",
    "    plt.subplot(4,4,idx)\n",
    "    idx+=1\n",
    "    plt.imshow(x1[i].reshape(128,128,3))\n",
    "    plt.subplot(4,4,idx)\n",
    "    # plt.axis('off')\n",
    "    # label = y1[i]\n",
    "    plt.imshow(io.imread(os.path.join(train_generator.directory,train_generator.filenames[(train_generator.batch_index-1)*32+i])))\n",
    "    idx+=1\n",
    "\n",
    "# plt.imshow(x1[1].numpy().astype('uint8'))\n",
    "plt.savefig('./visual_original_comp.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "90e92b14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e70150a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
